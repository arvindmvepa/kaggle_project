{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.run import run_experiment\n",
    "from exp.mappings import alg_map\n",
    "from exp.train import train_model\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper-parameter experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example of Cartesian Product of Hyper-parameters for Linear Regression\n",
    "\n",
    "\"lr\": {\"fit_intercept\": [False, True], \"normalize\": [False, True]}\n",
    "\n",
    "Cartesian Product: {fit_intercept} x {normalize}\n",
    "\n",
    "Hyper-parameter choices:\n",
    "\"fit_intercept\": False, \"normalize\": False\n",
    "\"fit_intercept\": True, \"normalize\": False\n",
    "\"fit_intercept\": False, \"normalize\": True\n",
    "\"fit_intercept\": True, \"normalize\": True\n",
    "\"\"\"\n",
    "params={\"svr\": {\"C\": [.001, .01, .1, 1.0, 1.0, 1.0, 10.0, 100.0],\n",
    "                \"shrinking\": [True, True, True, True, False],\n",
    "                \"kernel\": [\"rbf\"],\n",
    "                \"gamma\": [\"auto\", \"auto\", \"auto\", \"auto\", .001, .0001, .01, .1]},\n",
    "        \"nsvr\": {\"C\": [.001, .01, .1, 1.0, 1.0, 1.0, 10.0, 100.0],\n",
    "                 \"shrinking\": [True, True, True, True, False],\n",
    "                 \"kernel\": [\"rbf\"],\n",
    "                 \"gamma\": [\"auto\", \"auto\", \"auto\", \"auto\", .001, .0001, .01, .1]},\n",
    "        \"lsvr\": {\"C\": [.001, .01, .1, 1.0, 1.0, 1.0, 10.0, 100.0],\n",
    "                 \"epsilon\": [0],\n",
    "                 \"loss\": [\"epsilon_insensitive\", \"epsilon_insensitive\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "                 \"fit_intercept\": [True, True, True, False],\n",
    "                 \"intercept_scaling\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, .3, .6, 1.3, 1.6, 2.0],\n",
    "                 \"dual\": [True]},\n",
    "        \"knreg\": {\"n_neighbors\": [1, 3, 5, 10, 20],\n",
    "                  \"weights\": [\"uniform\", \"distance\"],\n",
    "                  \"leaf_size\": [5, 10, 20, 30, 40, 50, 60, 100],\n",
    "                  \"p\": [2,2,2,2,1,1,3,5]},\n",
    "        \"gpreg\": {\"alpha\": [1e-10, 1e-10, 1e-10, 1e-10, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2, .1],\n",
    "                  \"normalize_y\": [False, False, False, False, True]},\n",
    "        \"plsreg\": {\"n_components\": [2, 2, 2, 1, 5, 10],\n",
    "                   \"scale\": [True, True, True, True, False]},\n",
    "        \"dtreg\": {\"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "                  \"splitter\": [\"best\", \"best\", \"random\"],\n",
    "                  \"max_depth\": [None, None, None, 5,10,20,50]},\n",
    "        \"bagreg\": {\"n_estimators\": [5, 10, 50, 100, 200],\n",
    "                   \"max_samples\": [1.0, 1.0, .2, .5]},\n",
    "        \"rfreg\": {\"n_estimators\": [5, 10, 50, 100, 200],\n",
    "                  \"criterion\": [\"mse\"],\n",
    "                  \"max_depth\": [None, None, None, 5,10,20,50]},\n",
    "        \"etreg\": {\"n_estimators\": [5, 10, 50, 100, 200],\n",
    "                  \"criterion\": [\"mse\"],\n",
    "                  \"max_depth\": [None, None, None, 5,10,20,50]},\n",
    "        \"abreg\": {\"n_estimators\": [5, 10, 50, 100, 200],\n",
    "                  \"learning_rate\": [1, .9, .5, .1],\n",
    "                  \"loss\": [\"linear\", \"square\", \"exponential\"]},\n",
    "        \"gbreg\": {\"n_estimators\": [5, 10, 50, 100, 200],\n",
    "                  \"learning_rate\": [.5, .1, .01, .001],\n",
    "                  \"loss\": [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "                  \"subsample\": [.1, .2, .5, 1.0],\n",
    "                  \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "                  \"max_depth\": [3, 3, 3, 2, 5, 10]},\n",
    "        \"mlpreg\": {\"hidden_layer_sizes\":[(100,), (50,), (50, 50), (100, 100), (50, 50, 50), (100, 100, 100)],\n",
    "                   \"activation\": ['logistic', 'tanh', \"relu\", \"relu\", \"relu\", \"relu\"],\n",
    "                   \"solver\": [\"lbfgs\",\"sgd\", \"adam\", \"adam\"],\n",
    "                   \"batch_size\": [16, 32, 64, 128, 256, 512],\n",
    "                   \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "                   \"learning_rate_init\": [.1, .01, .001, .0001, .00001]}\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_searches=20\n",
    "n_fold=10\n",
    "save_results= \"exp2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in params.keys():\n",
    "    print(alg)\n",
    "    score_df = run_experiment(n_fold=n_fold, alg=alg, alg_params=params[alg], search_type=\"random\", num_searches=num_searches, save_results=save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display models ranked by CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = score_df.sort_values(by=\"cv_score_n_folds_10_shuffle_True_rs_None\", axis=0)\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results from CSV File and re-produce models ranked by CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_csv(save_results)\n",
    "score_df = score_df.sort_values(by=\"cv_score_n_folds_10_shuffle_True_rs_None\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve top scoring row\n",
    "best = score_df.iloc[0]\n",
    "display(best)\n",
    "\n",
    "# retrieve model parameters from pandas row\n",
    "alg = best[\"alg\"]\n",
    "params_json = best[\"params_json\"]\n",
    "fs = best[\"feature_set\"]\n",
    "\n",
    "print(\"alg: {}\".format(alg))\n",
    "print(\"params_json: {}\".format(params_json))\n",
    "print(\"feature_set: {}\".format(fs))\n",
    "\n",
    "# retrieve relevant values\n",
    "alg_cls = alg_map[alg]\n",
    "params = json.loads(params_json)\n",
    "\n",
    "# train algorithm\n",
    "train_model(params=params, fs=fs, n_fold=n_fold, alg=alg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
