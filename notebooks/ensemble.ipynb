{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>alg</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>filename</th>\n",
       "      <th>mad</th>\n",
       "      <th>n_folds</th>\n",
       "      <th>params_json</th>\n",
       "      <th>rs</th>\n",
       "      <th>score</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>221</td>\n",
       "      <td>lgb</td>\n",
       "      <td>24000_lgb_tree_20</td>\n",
       "      <td>exp8_1.csv</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 1.0, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp8_1.csv_221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>148</td>\n",
       "      <td>lgb</td>\n",
       "      <td>24000_lgb_tree_20</td>\n",
       "      <td>exp8_1.csv</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 10, ...</td>\n",
       "      <td>41</td>\n",
       "      <td>1.037952</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp8_1.csv_148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>188</td>\n",
       "      <td>lgb</td>\n",
       "      <td>24000_lgb_tree_15</td>\n",
       "      <td>exp8_1.csv</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>1.071727</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp8_1.csv_188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>42</td>\n",
       "      <td>lgb</td>\n",
       "      <td>24000_lgb_tree_100</td>\n",
       "      <td>exp8_1.csv</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>1.072742</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp8_1.csv_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>108</td>\n",
       "      <td>lgb</td>\n",
       "      <td>24000_lgb_tree_5</td>\n",
       "      <td>exp8_1.csv</td>\n",
       "      <td>0.016937</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 0, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>1.134979</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp8_1.csv_108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  alg         feature_set    filename       mad  n_folds  \\\n",
       "2107   221  lgb   24000_lgb_tree_20  exp8_1.csv  0.016741     10.0   \n",
       "2034   148  lgb   24000_lgb_tree_20  exp8_1.csv  0.022184     10.0   \n",
       "2074   188  lgb   24000_lgb_tree_15  exp8_1.csv  0.024104     10.0   \n",
       "1928    42  lgb  24000_lgb_tree_100  exp8_1.csv  0.009734     10.0   \n",
       "1994   108  lgb    24000_lgb_tree_5  exp8_1.csv  0.016937     10.0   \n",
       "\n",
       "                                            params_json  rs     score shuffle  \\\n",
       "2107  {\"bagging_fraction\": 1.0, \"bagging_freq\": 5, \"...  41  0.990926    True   \n",
       "2034  {\"bagging_fraction\": 0.8, \"bagging_freq\": 10, ...  41  1.037952    True   \n",
       "2074  {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  1.071727    True   \n",
       "1928  {\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...  41  1.072742    True   \n",
       "1994  {\"bagging_fraction\": 0.8, \"bagging_freq\": 0, \"...  41  1.134979    True   \n",
       "\n",
       "                model_id  \n",
       "2107  lgb_exp8_1.csv_221  \n",
       "2034  lgb_exp8_1.csv_148  \n",
       "2074  lgb_exp8_1.csv_188  \n",
       "1928   lgb_exp8_1.csv_42  \n",
       "1994  lgb_exp8_1.csv_108  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from math import factorial\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from exp.train import train_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from exp.features import load_cv_results\n",
    "\n",
    "save_results= \"exp1.csv\"\n",
    "score_df = load_cv_results(save_results)\n",
    "score_df['filename'] = save_results\n",
    "\n",
    "save_results= \"exp2.csv\"\n",
    "tmp = load_cv_results(save_results)\n",
    "tmp['filename'] = save_results\n",
    "score_df = score_df.append(tmp)\n",
    "\n",
    "save_results= \"exp3.csv\"\n",
    "tmp = load_cv_results(save_results)\n",
    "tmp['filename'] = save_results\n",
    "score_df = score_df.append(tmp)\n",
    "score_df[\"feature_set\"] = \"standard_scaled\"\n",
    "\n",
    "save_results= \"exp4_1.csv\"\n",
    "score_df_ = load_cv_results(save_results)\n",
    "score_df_['filename'] = save_results\n",
    "score_df_ = score_df_.rename(index=str, columns={\"cv_score_n_folds_10_shuffle_True_rs_41\": \"score\"})\n",
    "score_df_['n_folds'] = 10\n",
    "score_df_['shuffle'] = True\n",
    "score_df_['rs'] = 41\n",
    "score_df = score_df.append(score_df_)\n",
    "\n",
    "save_results= \"exp5.csv\"\n",
    "score_df_ = load_cv_results(save_results)\n",
    "score_df_['filename'] = save_results\n",
    "score_df_ = score_df_.rename(index=str, columns={\"cv_score_n_folds_10_shuffle_True_rs_41\": \"score\"})\n",
    "score_df_['n_folds'] = 10\n",
    "score_df_['shuffle'] = True\n",
    "score_df_['rs'] = 41\n",
    "score_df = score_df.append(score_df_)\n",
    "\n",
    "save_results= \"exp6.csv\"\n",
    "score_df_ = load_cv_results(save_results)\n",
    "score_df_['filename'] = save_results\n",
    "score_df_ = score_df_.rename(index=str, columns={\"cv_score_n_folds_10_shuffle_True_rs_41\": \"score\"})\n",
    "score_df_['n_folds'] = 10\n",
    "score_df_['shuffle'] = True\n",
    "score_df_['rs'] = 41\n",
    "score_df = score_df.append(score_df_)\n",
    "\n",
    "save_results= \"exp7.csv\"\n",
    "score_df_ = load_cv_results(save_results)\n",
    "score_df_['filename'] = save_results\n",
    "score_df_ = score_df_.rename(index=str, columns={\"cv_score_n_folds_10_shuffle_True_rs_41\": \"score\"})\n",
    "score_df_['n_folds'] = 10\n",
    "score_df_['shuffle'] = True\n",
    "score_df_['rs'] = 41\n",
    "score_df = score_df.append(score_df_)\n",
    "\n",
    "save_results= \"exp8_1.csv\"\n",
    "score_df_ = load_cv_results(save_results)\n",
    "score_df_['filename'] = save_results\n",
    "score_df_ = score_df_.rename(index=str, columns={\"cv_score_n_folds_10_shuffle_True_rs_41\": \"score\"})\n",
    "score_df_['n_folds'] = 10\n",
    "score_df_['shuffle'] = True\n",
    "score_df_['rs'] = 41\n",
    "score_df = score_df.append(score_df_)\n",
    "\n",
    "save_results= \"exp8_2.csv\"\n",
    "score_df_ = load_cv_results(save_results)\n",
    "score_df_['filename'] = save_results\n",
    "score_df_ = score_df_.rename(index=str, columns={\"cv_score_n_folds_6_shuffle_False_rs_41\": \"score\"})\n",
    "score_df_['n_folds'] = 6\n",
    "score_df_['shuffle'] = False\n",
    "score_df_['rs'] = 41\n",
    "score_df = score_df.append(score_df_)\n",
    "\n",
    "save_results= \"exp9.csv\"\n",
    "score_df_ = load_cv_results(save_results)\n",
    "score_df_['filename'] = save_results\n",
    "score_df_ = score_df_.rename(index=str, columns={\"cv_score_n_folds_5_shuffle_False_rs_None\": \"score\"})\n",
    "score_df_['n_folds'] = 5\n",
    "score_df_['shuffle'] = False\n",
    "score_df_['rs'] = None\n",
    "score_df = score_df.append(score_df_)\n",
    "\n",
    "score_df.reset_index(inplace=True)\n",
    "\n",
    "score_df['model_id'] = score_df['index'].astype(str)\n",
    "score_df['model_id'] = score_df[['alg','filename','model_id']].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "score_df = score_df.sort_values(by=\"score\", axis=0)\n",
    "\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Models to Obtain OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_24k = score_df['feature_set'].apply(lambda x: not x.startswith('2400'))\n",
    "fourK_set = score_df.loc[non_24k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>alg</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>filename</th>\n",
       "      <th>mad</th>\n",
       "      <th>n_folds</th>\n",
       "      <th>params_json</th>\n",
       "      <th>rs</th>\n",
       "      <th>score</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>884</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.058856</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.016929</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>123</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled_pc_0.05</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.020700</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>929</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.050516</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.021247</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>873</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.055442</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.023506</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>18</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled_pc_0.05</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.047044</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 1.0, \"bagging_freq\": 10, ...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.026146</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>953</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.049677</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.026580</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>868</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.034619</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.026777</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>866</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.046534</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.027478</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>150</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled_pc_0.01</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.040422</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.028170</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>96</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.028190</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>22</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled_pc_0.05</td>\n",
       "      <td>exp6.csv</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 1.0, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.028314</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp6.csv_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>148</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.040722</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.028877</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>951</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.063879</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 1.0, \"bagging_freq\": 0, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.028933</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>109</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.028996</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>136</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled_pc_0.01</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.038791</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.5, \"bagging_freq\": 0, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.029171</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  alg                feature_set  filename       mad  n_folds  \\\n",
       "1810   884  lgb  more_features_lgb_eli_100  exp7.csv  0.058856     10.0   \n",
       "825    123  lgb    standard_scaled_pc_0.05  exp5.csv  0.041500     10.0   \n",
       "1855   929  lgb  more_features_lgb_eli_100  exp7.csv  0.050516     10.0   \n",
       "1799   873  lgb  more_features_lgb_eli_100  exp7.csv  0.055442     10.0   \n",
       "720     18  lgb    standard_scaled_pc_0.05  exp5.csv  0.047044     10.0   \n",
       "1879   953  lgb  more_features_lgb_eli_100  exp7.csv  0.049677     10.0   \n",
       "1794   868  lgb  more_features_lgb_eli_100  exp7.csv  0.034619     10.0   \n",
       "1792   866  lgb  more_features_lgb_eli_100  exp7.csv  0.046534     10.0   \n",
       "852    150  lgb    standard_scaled_pc_0.01  exp5.csv  0.040422     10.0   \n",
       "798     96  lgb            standard_scaled  exp5.csv  0.030177     10.0   \n",
       "924     22  lgb    standard_scaled_pc_0.05  exp6.csv  0.031010     10.0   \n",
       "850    148  lgb            standard_scaled  exp5.csv  0.040722     10.0   \n",
       "1877   951  lgb  more_features_lgb_eli_100  exp7.csv  0.063879     10.0   \n",
       "811    109  lgb            standard_scaled  exp5.csv  0.025882     10.0   \n",
       "838    136  lgb    standard_scaled_pc_0.01  exp5.csv  0.038791     10.0   \n",
       "\n",
       "                                            params_json  rs     score shuffle  \\\n",
       "1810  {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.016929    True   \n",
       "825   {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.020700    True   \n",
       "1855  {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.021247    True   \n",
       "1799  {\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...  41  2.023506    True   \n",
       "720   {\"bagging_fraction\": 1.0, \"bagging_freq\": 10, ...  41  2.026146    True   \n",
       "1879  {\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...  41  2.026580    True   \n",
       "1794  {\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...  41  2.026777    True   \n",
       "1792  {\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...  41  2.027478    True   \n",
       "852   {\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...  41  2.028170    True   \n",
       "798   {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.028190    True   \n",
       "924   {\"bagging_fraction\": 1.0, \"bagging_freq\": 5, \"...  41  2.028314    True   \n",
       "850   {\"bagging_fraction\": 0.8, \"bagging_freq\": 2, \"...  41  2.028877    True   \n",
       "1877  {\"bagging_fraction\": 1.0, \"bagging_freq\": 0, \"...  41  2.028933    True   \n",
       "811   {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.028996    True   \n",
       "838   {\"bagging_fraction\": 0.5, \"bagging_freq\": 0, \"...  41  2.029171    True   \n",
       "\n",
       "              model_id  \n",
       "1810  lgb_exp7.csv_884  \n",
       "825   lgb_exp5.csv_123  \n",
       "1855  lgb_exp7.csv_929  \n",
       "1799  lgb_exp7.csv_873  \n",
       "720    lgb_exp5.csv_18  \n",
       "1879  lgb_exp7.csv_953  \n",
       "1794  lgb_exp7.csv_868  \n",
       "1792  lgb_exp7.csv_866  \n",
       "852   lgb_exp5.csv_150  \n",
       "798    lgb_exp5.csv_96  \n",
       "924    lgb_exp6.csv_22  \n",
       "850   lgb_exp5.csv_148  \n",
       "1877  lgb_exp7.csv_951  \n",
       "811   lgb_exp5.csv_109  \n",
       "838   lgb_exp5.csv_136  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourK_set.sort_values('score', inplace=True)\n",
    "fourK_set.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1810,  825, 1855, 1799,  720, 1879, 1794, 1792,  852,  798,  924,\n",
       "             850, 1877,  811,  838],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OOF_list = fourK_set['score'].head(15).index\n",
    "OOF_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_params(model_exp):\n",
    "    model_dict = {}\n",
    "    \n",
    "    model_dict['params'] = json.loads(model_exp['params_json'])\n",
    "    model_dict['fs'] = model_exp['feature_set']\n",
    "    model_dict['alg'] = model_exp['alg']\n",
    "    model_dict['rs'] = RANDOM_SEED\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_params = []\n",
    "for model_idx in OOF_list:\n",
    "    oof_params.append(get_train_params(score_df.loc[model_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'min_data_in_leaf': 80,\n",
       "   'n_estimators': 3000,\n",
       "   'num_leaves': 25,\n",
       "   'objective': 'mae',\n",
       "   'reg_alpha': 0.4,\n",
       "   'reg_lambda': 0.0,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'more_features_lgb_eli_100',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 400, 'test_size': 0.2},\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': -1,\n",
       "   'min_data_in_leaf': 40,\n",
       "   'n_estimators': 3000,\n",
       "   'num_leaves': 10,\n",
       "   'objective': 'mae',\n",
       "   'reg_alpha': 0.0,\n",
       "   'reg_lambda': 0.01,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled_pc_0.05',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': -1,\n",
       "   'min_data_in_leaf': 20,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 25,\n",
       "   'objective': 'mae',\n",
       "   'reg_alpha': 0.001,\n",
       "   'reg_lambda': 0.2,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'more_features_lgb_eli_100',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 2,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 400, 'test_size': 0.1},\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'min_data_in_leaf': 20,\n",
       "   'n_estimators': 5000,\n",
       "   'num_leaves': 25,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.0,\n",
       "   'reg_lambda': 0.35,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'more_features_lgb_eli_100',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 1.0,\n",
       "   'bagging_freq': 10,\n",
       "   'boosting': 'gbdt',\n",
       "   'learning_rate': 0.001,\n",
       "   'max_depth': 5,\n",
       "   'min_data_in_leaf': 80,\n",
       "   'n_estimators': 5000,\n",
       "   'num_leaves': 100,\n",
       "   'objective': 'mae',\n",
       "   'reg_alpha': 0.001,\n",
       "   'reg_lambda': 0.4,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled_pc_0.05',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.5,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': -1,\n",
       "   'min_data_in_leaf': 160,\n",
       "   'n_estimators': 2000,\n",
       "   'num_leaves': 10,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.4,\n",
       "   'reg_lambda': 0.35,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'more_features_lgb_eli_100',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 2,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 400, 'test_size': 0.1},\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': -1,\n",
       "   'min_data_in_leaf': 80,\n",
       "   'n_estimators': 10000,\n",
       "   'num_leaves': 25,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.001,\n",
       "   'reg_lambda': 0.01,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'more_features_lgb_eli_100',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.5,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 400, 'test_size': 0.1},\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 20,\n",
       "   'min_data_in_leaf': 80,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 100,\n",
       "   'objective': 'mae',\n",
       "   'reg_alpha': 0.4,\n",
       "   'reg_lambda': 0.0,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'more_features_lgb_eli_100',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.5,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 400, 'test_size': 0.1},\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'min_data_in_leaf': 20,\n",
       "   'n_estimators': 5000,\n",
       "   'num_leaves': 5,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.001,\n",
       "   'reg_lambda': 0.2,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled_pc_0.01',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'min_data_in_leaf': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 5,\n",
       "   'objective': 'mae',\n",
       "   'reg_alpha': 0.15,\n",
       "   'reg_lambda': 0.35,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 1.0,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 400, 'test_size': 0.1},\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_data_in_leaf': 200,\n",
       "   'n_estimators': 50000,\n",
       "   'num_leaves': 75,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.4,\n",
       "   'reg_lambda': 0.0,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled_pc_0.05',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 2,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 400, 'test_size': 0.1},\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'min_data_in_leaf': 20,\n",
       "   'n_estimators': 2000,\n",
       "   'num_leaves': 5,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.01,\n",
       "   'reg_lambda': 0.01,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 1.0,\n",
       "   'bagging_freq': 0,\n",
       "   'boosting': 'gbdt',\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 20,\n",
       "   'min_data_in_leaf': 160,\n",
       "   'n_estimators': 2000,\n",
       "   'num_leaves': 10,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.4,\n",
       "   'reg_lambda': 0.4,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'more_features_lgb_eli_100',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.8,\n",
       "   'bagging_freq': 5,\n",
       "   'boosting': 'gbdt',\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'min_data_in_leaf': 20,\n",
       "   'n_estimators': 2000,\n",
       "   'num_leaves': 10,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.4,\n",
       "   'reg_lambda': 0.0,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42},\n",
       " {'params': {'bagging_fraction': 0.5,\n",
       "   'bagging_freq': 0,\n",
       "   'boosting': 'gbdt',\n",
       "   'early_stopping': {'early_stopping_rounds': 200, 'test_size': 0.1},\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 20,\n",
       "   'min_data_in_leaf': 20,\n",
       "   'n_estimators': 10000,\n",
       "   'num_leaves': 10,\n",
       "   'objective': 'huber',\n",
       "   'reg_alpha': 0.4,\n",
       "   'reg_lambda': 0.2,\n",
       "   'verbosity': -1},\n",
       "  'fs': 'standard_scaled_pc_0.01',\n",
       "  'alg': 'lgb',\n",
       "  'rs': 42}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sun Jun  2 20:48:07 2019\n",
      "Fold 0. MAE: 2.1045.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:48:14 2019\n",
      "Fold 1. MAE: 2.0345.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:48:23 2019\n",
      "Fold 2. MAE: 1.9491.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:48:30 2019\n",
      "Fold 3. MAE: 2.1240.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:48:37 2019\n",
      "Fold 4. MAE: 2.0148.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:48:44 2019\n",
      "Fold 5. MAE: 2.0689.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:48:50 2019\n",
      "Fold 6. MAE: 2.0136.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:48:56 2019\n",
      "Fold 7. MAE: 1.8997.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:49:02 2019\n",
      "Fold 8. MAE: 1.9747.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:49:08 2019\n",
      "Fold 9. MAE: 2.0747.\n",
      "\n",
      "CV mean score: 2.0258, mad: 0.0741.\n",
      "Fold 0 started at Sun Jun  2 20:49:15 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[605]\tvalid_0's l1: 1.99733\n",
      "Fold 0. MAE: 2.0897.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:49:16 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's l1: 1.97726\n",
      "Fold 1. MAE: 1.9901.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:49:17 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1590]\tvalid_0's l1: 2.02403\n",
      "Fold 2. MAE: 2.0544.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:49:19 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's l1: 2.0352\n",
      "Fold 3. MAE: 2.1217.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:49:20 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's l1: 2.0198\n",
      "Fold 4. MAE: 1.9965.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:49:21 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's l1: 2.01581\n",
      "Fold 5. MAE: 2.0328.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:49:22 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's l1: 1.90115\n",
      "Fold 6. MAE: 1.9954.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:49:23 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[568]\tvalid_0's l1: 1.96499\n",
      "Fold 7. MAE: 1.9458.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:49:25 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[530]\tvalid_0's l1: 2.03582\n",
      "Fold 8. MAE: 2.0471.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:49:26 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[407]\tvalid_0's l1: 2.05049\n",
      "Fold 9. MAE: 2.0447.\n",
      "\n",
      "CV mean score: 2.0318, mad: 0.0635.\n",
      "Fold 0 started at Sun Jun  2 20:49:27 2019\n",
      "Fold 0. MAE: 2.1092.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:49:30 2019\n",
      "Fold 1. MAE: 2.0170.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:49:34 2019\n",
      "Fold 2. MAE: 1.9782.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:49:38 2019\n",
      "Fold 3. MAE: 2.1167.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:49:42 2019\n",
      "Fold 4. MAE: 2.0326.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:49:45 2019\n",
      "Fold 5. MAE: 2.0506.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:49:48 2019\n",
      "Fold 6. MAE: 1.9919.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:49:51 2019\n",
      "Fold 7. MAE: 1.9172.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:49:54 2019\n",
      "Fold 8. MAE: 1.9902.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:49:57 2019\n",
      "Fold 9. MAE: 2.0921.\n",
      "\n",
      "CV mean score: 2.0296, mad: 0.0602.\n",
      "Fold 0 started at Sun Jun  2 20:50:00 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1576]\tvalid_0's l1: 1.86795\tvalid_0's huber: 1.32538\n",
      "Fold 0. MAE: 2.1087.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:50:08 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2070]\tvalid_0's l1: 2.07064\tvalid_0's huber: 1.49941\n",
      "Fold 1. MAE: 2.0150.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:50:17 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[912]\tvalid_0's l1: 1.99091\tvalid_0's huber: 1.42085\n",
      "Fold 2. MAE: 1.9942.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:50:22 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1241]\tvalid_0's l1: 1.92651\tvalid_0's huber: 1.3744\n",
      "Fold 3. MAE: 2.1404.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:50:30 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1932]\tvalid_0's l1: 1.96919\tvalid_0's huber: 1.41178\n",
      "Fold 4. MAE: 2.0326.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:50:38 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1160]\tvalid_0's l1: 2.069\tvalid_0's huber: 1.49625\n",
      "Fold 5. MAE: 2.0432.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:50:44 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1334]\tvalid_0's l1: 1.98141\tvalid_0's huber: 1.42315\n",
      "Fold 6. MAE: 2.0016.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:50:51 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1418]\tvalid_0's l1: 2.05736\tvalid_0's huber: 1.49834\n",
      "Fold 7. MAE: 1.8998.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:50:57 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1477]\tvalid_0's l1: 1.96802\tvalid_0's huber: 1.41081\n",
      "Fold 8. MAE: 2.0036.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:51:04 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1268]\tvalid_0's l1: 1.95672\tvalid_0's huber: 1.40062\n",
      "Fold 9. MAE: 2.0798.\n",
      "\n",
      "CV mean score: 2.0319, mad: 0.0383.\n",
      "Fold 0 started at Sun Jun  2 20:51:09 2019\n",
      "Fold 0. MAE: 2.1095.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:51:16 2019\n",
      "Fold 1. MAE: 1.9714.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:51:22 2019\n",
      "Fold 2. MAE: 2.0496.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:51:29 2019\n",
      "Fold 3. MAE: 2.1095.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:51:37 2019\n",
      "Fold 4. MAE: 1.9775.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:51:44 2019\n",
      "Fold 5. MAE: 2.0274.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:51:50 2019\n",
      "Fold 6. MAE: 2.0026.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:51:58 2019\n",
      "Fold 7. MAE: 1.9496.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:52:05 2019\n",
      "Fold 8. MAE: 2.0698.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:52:12 2019\n",
      "Fold 9. MAE: 2.0332.\n",
      "\n",
      "CV mean score: 2.0300, mad: 0.0684.\n",
      "Fold 0 started at Sun Jun  2 20:52:20 2019\n",
      "Fold 0. MAE: 2.1056.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:52:22 2019\n",
      "Fold 1. MAE: 2.0194.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:52:24 2019\n",
      "Fold 2. MAE: 1.9777.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:52:26 2019\n",
      "Fold 3. MAE: 2.1275.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:52:28 2019\n",
      "Fold 4. MAE: 2.0141.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:52:30 2019\n",
      "Fold 5. MAE: 2.0483.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:52:32 2019\n",
      "Fold 6. MAE: 2.0030.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:52:34 2019\n",
      "Fold 7. MAE: 1.8978.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:52:36 2019\n",
      "Fold 8. MAE: 2.0045.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:52:37 2019\n",
      "Fold 9. MAE: 2.0720.\n",
      "\n",
      "CV mean score: 2.0270, mad: 0.0523.\n",
      "Fold 0 started at Sun Jun  2 20:52:39 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[964]\tvalid_0's l1: 2.02205\tvalid_0's huber: 1.45492\n",
      "Fold 0. MAE: 2.1179.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:52:42 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1368]\tvalid_0's l1: 2.00509\tvalid_0's huber: 1.43658\n",
      "Fold 1. MAE: 2.0088.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:52:47 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1930]\tvalid_0's l1: 2.1117\tvalid_0's huber: 1.53875\n",
      "Fold 2. MAE: 1.9627.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:52:52 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1136]\tvalid_0's l1: 1.95708\tvalid_0's huber: 1.40064\n",
      "Fold 3. MAE: 2.1391.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:52:56 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1732]\tvalid_0's l1: 2.09919\tvalid_0's huber: 1.51935\n",
      "Fold 4. MAE: 2.0206.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:53:02 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1952]\tvalid_0's l1: 2.16622\tvalid_0's huber: 1.58134\n",
      "Fold 5. MAE: 2.0694.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:53:08 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[982]\tvalid_0's l1: 1.94958\tvalid_0's huber: 1.39296\n",
      "Fold 6. MAE: 2.0039.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:53:11 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1795]\tvalid_0's l1: 2.0209\tvalid_0's huber: 1.45126\n",
      "Fold 7. MAE: 1.9064.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:53:17 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1534]\tvalid_0's l1: 2.05615\tvalid_0's huber: 1.48706\n",
      "Fold 8. MAE: 2.0009.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:53:21 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1516]\tvalid_0's l1: 2.1902\tvalid_0's huber: 1.60536\n",
      "Fold 9. MAE: 2.0779.\n",
      "\n",
      "CV mean score: 2.0308, mad: 0.0791.\n",
      "Fold 0 started at Sun Jun  2 20:53:25 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid_0's l1: 2.1047\n",
      "Fold 0. MAE: 2.1260.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:53:26 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[777]\tvalid_0's l1: 2.00171\n",
      "Fold 1. MAE: 2.0282.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:53:28 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's l1: 1.98074\n",
      "Fold 2. MAE: 1.9658.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:53:29 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[875]\tvalid_0's l1: 2.03807\n",
      "Fold 3. MAE: 2.1282.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:53:30 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's l1: 2.12428\n",
      "Fold 4. MAE: 2.0279.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:53:32 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[950]\tvalid_0's l1: 2.10649\n",
      "Fold 5. MAE: 2.0543.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:53:33 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[887]\tvalid_0's l1: 1.99742\n",
      "Fold 6. MAE: 2.0231.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:53:35 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[880]\tvalid_0's l1: 2.01237\n",
      "Fold 7. MAE: 1.8888.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:53:36 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[973]\tvalid_0's l1: 2.04451\n",
      "Fold 8. MAE: 1.9885.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:53:38 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[841]\tvalid_0's l1: 1.93974\n",
      "Fold 9. MAE: 2.0884.\n",
      "\n",
      "CV mean score: 2.0319, mad: 0.0740.\n",
      "Fold 0 started at Sun Jun  2 20:53:39 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1730]\tvalid_0's l1: 2.0668\tvalid_0's huber: 1.48384\n",
      "Fold 0. MAE: 2.0885.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:53:41 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1745]\tvalid_0's l1: 2.02231\tvalid_0's huber: 1.45248\n",
      "Fold 1. MAE: 1.9806.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:53:42 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1550]\tvalid_0's l1: 2.07028\tvalid_0's huber: 1.50021\n",
      "Fold 2. MAE: 2.0511.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:53:43 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1580]\tvalid_0's l1: 2.04798\tvalid_0's huber: 1.47618\n",
      "Fold 3. MAE: 2.1014.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:53:45 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1207]\tvalid_0's l1: 1.89821\tvalid_0's huber: 1.35021\n",
      "Fold 4. MAE: 2.0045.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:53:46 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1425]\tvalid_0's l1: 1.90109\tvalid_0's huber: 1.35066\n",
      "Fold 5. MAE: 2.0244.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:53:47 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1405]\tvalid_0's l1: 1.93437\tvalid_0's huber: 1.37146\n",
      "Fold 6. MAE: 2.0088.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:53:48 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1580]\tvalid_0's l1: 2.12269\tvalid_0's huber: 1.54665\n",
      "Fold 7. MAE: 1.9373.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:53:50 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2300]\tvalid_0's l1: 2.02948\tvalid_0's huber: 1.45595\n",
      "Fold 8. MAE: 2.0538.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:53:52 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[830]\tvalid_0's l1: 1.98276\tvalid_0's huber: 1.4196\n",
      "Fold 9. MAE: 2.0565.\n",
      "\n",
      "CV mean score: 2.0307, mad: 0.0461.\n",
      "Fold 0 started at Sun Jun  2 20:53:53 2019\n",
      "Fold 0. MAE: 2.0988.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:53:54 2019\n",
      "Fold 1. MAE: 1.9768.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:53:54 2019\n",
      "Fold 2. MAE: 2.0419.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:53:56 2019\n",
      "Fold 3. MAE: 2.0998.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:53:57 2019\n",
      "Fold 4. MAE: 2.0008.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:53:57 2019\n",
      "Fold 5. MAE: 2.0369.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:53:58 2019\n",
      "Fold 6. MAE: 1.9921.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:53:59 2019\n",
      "Fold 7. MAE: 1.9466.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:54:00 2019\n",
      "Fold 8. MAE: 2.0642.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:54:01 2019\n",
      "Fold 9. MAE: 2.0535.\n",
      "\n",
      "CV mean score: 2.0311, mad: 0.0637.\n",
      "Fold 0 started at Sun Jun  2 20:54:03 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l1: 1.98924\tvalid_0's huber: 1.42572\n",
      "Fold 0. MAE: 2.1080.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:54:03 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's l1: 2.02344\tvalid_0's huber: 1.45851\n",
      "Fold 1. MAE: 1.9921.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:54:04 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's l1: 2.00348\tvalid_0's huber: 1.43235\n",
      "Fold 2. MAE: 2.0506.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:54:04 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's l1: 1.97881\tvalid_0's huber: 1.41908\n",
      "Fold 3. MAE: 2.0899.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:54:05 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's l1: 2.07483\tvalid_0's huber: 1.50547\n",
      "Fold 4. MAE: 1.9867.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:54:06 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's l1: 2.08047\tvalid_0's huber: 1.49653\n",
      "Fold 5. MAE: 2.0195.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:54:06 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l1: 1.988\tvalid_0's huber: 1.42981\n",
      "Fold 6. MAE: 2.0296.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:54:07 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's l1: 2.09292\tvalid_0's huber: 1.51382\n",
      "Fold 7. MAE: 1.9534.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:54:07 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[381]\tvalid_0's l1: 2.08589\tvalid_0's huber: 1.50832\n",
      "Fold 8. MAE: 2.0819.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:54:08 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's l1: 2.01718\tvalid_0's huber: 1.44806\n",
      "Fold 9. MAE: 2.0457.\n",
      "\n",
      "CV mean score: 2.0357, mad: 0.0666.\n",
      "Fold 0 started at Sun Jun  2 20:54:09 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[718]\tvalid_0's l1: 2.01885\tvalid_0's huber: 1.45197\n",
      "Fold 0. MAE: 2.1267.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:54:10 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1100]\tvalid_0's l1: 1.97701\tvalid_0's huber: 1.41798\n",
      "Fold 1. MAE: 1.9935.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:54:12 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1606]\tvalid_0's l1: 1.9962\tvalid_0's huber: 1.42109\n",
      "Fold 2. MAE: 2.0494.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:54:14 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1996]\tvalid_0's l1: 2.09149\tvalid_0's huber: 1.51259\n",
      "Fold 3. MAE: 2.0966.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:54:17 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1290]\tvalid_0's l1: 1.93212\tvalid_0's huber: 1.37394\n",
      "Fold 4. MAE: 2.0030.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:54:19 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1976]\tvalid_0's l1: 2.12776\tvalid_0's huber: 1.54726\n",
      "Fold 5. MAE: 2.0334.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:54:21 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1504]\tvalid_0's l1: 2.07711\tvalid_0's huber: 1.49741\n",
      "Fold 6. MAE: 2.0014.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:54:24 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 2.18288\tvalid_0's huber: 1.59428\n",
      "Fold 7. MAE: 1.9326.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:54:26 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 2.05433\tvalid_0's huber: 1.48734\n",
      "Fold 8. MAE: 2.0588.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:54:28 2019\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1144]\tvalid_0's l1: 1.94279\tvalid_0's huber: 1.38259\n",
      "Fold 9. MAE: 2.0506.\n",
      "\n",
      "CV mean score: 2.0346, mad: 0.0581.\n",
      "Fold 0 started at Sun Jun  2 20:54:29 2019\n",
      "Fold 0. MAE: 2.1006.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:54:31 2019\n",
      "Fold 1. MAE: 2.0081.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:54:34 2019\n",
      "Fold 2. MAE: 1.9768.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:54:36 2019\n",
      "Fold 3. MAE: 2.1480.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:54:39 2019\n",
      "Fold 4. MAE: 2.0443.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:54:41 2019\n",
      "Fold 5. MAE: 2.0713.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:54:44 2019\n",
      "Fold 6. MAE: 2.0039.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:54:47 2019\n",
      "Fold 7. MAE: 1.9032.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:54:49 2019\n",
      "Fold 8. MAE: 2.0012.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:54:51 2019\n",
      "Fold 9. MAE: 2.0733.\n",
      "\n",
      "CV mean score: 2.0331, mad: 0.0684.\n",
      "Fold 0 started at Sun Jun  2 20:54:54 2019\n",
      "Fold 0. MAE: 2.0848.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:54:57 2019\n",
      "Fold 1. MAE: 1.9762.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:55:00 2019\n",
      "Fold 2. MAE: 2.0451.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:55:03 2019\n",
      "Fold 3. MAE: 2.0938.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:55:06 2019\n",
      "Fold 4. MAE: 1.9885.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:55:09 2019\n",
      "Fold 5. MAE: 2.0468.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:55:12 2019\n",
      "Fold 6. MAE: 2.0065.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:55:15 2019\n",
      "Fold 7. MAE: 1.9468.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:55:18 2019\n",
      "Fold 8. MAE: 2.0573.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:55:22 2019\n",
      "Fold 9. MAE: 2.0341.\n",
      "\n",
      "CV mean score: 2.0280, mad: 0.0581.\n",
      "Fold 0 started at Sun Jun  2 20:55:25 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[639]\tvalid_0's l1: 1.9979\tvalid_0's huber: 1.42751\n",
      "Fold 0. MAE: 2.1294.\n",
      "\n",
      "Fold 1 started at Sun Jun  2 20:55:26 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2326]\tvalid_0's l1: 1.98487\tvalid_0's huber: 1.42031\n",
      "Fold 1. MAE: 1.9939.\n",
      "\n",
      "Fold 2 started at Sun Jun  2 20:55:30 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2259]\tvalid_0's l1: 2.09604\tvalid_0's huber: 1.51262\n",
      "Fold 2. MAE: 2.0345.\n",
      "\n",
      "Fold 3 started at Sun Jun  2 20:55:33 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1730]\tvalid_0's l1: 1.98299\tvalid_0's huber: 1.42218\n",
      "Fold 3. MAE: 2.1068.\n",
      "\n",
      "Fold 4 started at Sun Jun  2 20:55:35 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1267]\tvalid_0's l1: 2.09795\tvalid_0's huber: 1.52034\n",
      "Fold 4. MAE: 2.0266.\n",
      "\n",
      "Fold 5 started at Sun Jun  2 20:55:37 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1096]\tvalid_0's l1: 2.00152\tvalid_0's huber: 1.43558\n",
      "Fold 5. MAE: 2.0448.\n",
      "\n",
      "Fold 6 started at Sun Jun  2 20:55:39 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1803]\tvalid_0's l1: 2.18954\tvalid_0's huber: 1.60278\n",
      "Fold 6. MAE: 2.0046.\n",
      "\n",
      "Fold 7 started at Sun Jun  2 20:55:42 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1020]\tvalid_0's l1: 2.15072\tvalid_0's huber: 1.5684\n",
      "Fold 7. MAE: 1.9401.\n",
      "\n",
      "Fold 8 started at Sun Jun  2 20:55:44 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1171]\tvalid_0's l1: 1.85936\tvalid_0's huber: 1.30145\n",
      "Fold 8. MAE: 2.0774.\n",
      "\n",
      "Fold 9 started at Sun Jun  2 20:55:46 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1023]\tvalid_0's l1: 1.98262\tvalid_0's huber: 1.41653\n",
      "Fold 9. MAE: 2.0387.\n",
      "\n",
      "CV mean score: 2.0397, mad: 0.0539.\n"
     ]
    }
   ],
   "source": [
    "oof_preds = {}\n",
    "i=0\n",
    "for model_dict in oof_params:\n",
    "    _,_, oof = train_model(**model_dict)\n",
    "    oof_preds[OOF_list[i]] = oof\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_df = pd.DataFrame(oof_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_df.to_csv('oof_preds_rs42.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_average(ensemble_oof_preds):\n",
    "    return mean_absolute_error(ttf, np.mean(ensemble_oof_preds.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttf = pd.read_csv('../kaggle_files/features/train/ttf.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# N = 20 \n",
    "k_range = range(2,8)\n",
    "\n",
    "all_combinations = []\n",
    "for k in k_range:\n",
    "    print(k)\n",
    "#     top_k = itertools.combinations(oof_preds_df.columns[:N],k)\n",
    "    top_k = itertools.combinations(oof_preds_df.columns,k)\n",
    "    for combo in top_k:\n",
    "        all_combinations.append([combo,simple_average(oof_preds_df[list(combo)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations_df = pd.DataFrame(all_combinations, columns=['models','mean_cv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>mean_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1810, 811)</td>\n",
       "      <td>2.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1810, 720)</td>\n",
       "      <td>2.006598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>(1810, 720, 1792, 811)</td>\n",
       "      <td>2.007414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>(1810, 720, 1879, 811)</td>\n",
       "      <td>2.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1810, 825)</td>\n",
       "      <td>2.007633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>(1810, 1792, 924, 811)</td>\n",
       "      <td>2.007861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>(1810, 825, 1792, 811)</td>\n",
       "      <td>2.008015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>(1810, 825, 720, 1792)</td>\n",
       "      <td>2.008061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>(1810, 825, 1879, 811)</td>\n",
       "      <td>2.008103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>(1810, 825, 720, 1879)</td>\n",
       "      <td>2.008145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1810, 852)</td>\n",
       "      <td>2.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>(1810, 1879, 924, 811)</td>\n",
       "      <td>2.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>(1810, 825, 720, 1879, 1792, 811)</td>\n",
       "      <td>2.008208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>(1810, 720, 811)</td>\n",
       "      <td>2.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>(1810, 720, 1879, 1792, 924, 811)</td>\n",
       "      <td>2.008255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>(1810, 720, 1792, 924)</td>\n",
       "      <td>2.008256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>(1810, 720, 1792, 798)</td>\n",
       "      <td>2.008268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>(1810, 1855, 720, 811)</td>\n",
       "      <td>2.008288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>(1810, 720, 1792, 924, 811)</td>\n",
       "      <td>2.008303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>(1810, 1799, 720, 811)</td>\n",
       "      <td>2.008331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>(1810, 720, 1794, 811)</td>\n",
       "      <td>2.008357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>(1810, 720, 1879, 1792, 811)</td>\n",
       "      <td>2.008390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>(1810, 720, 1879, 924)</td>\n",
       "      <td>2.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>(1810, 825, 720, 1792, 811)</td>\n",
       "      <td>2.008435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>(1810, 720, 1792, 852)</td>\n",
       "      <td>2.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>(1810, 1855, 720, 1792, 924, 811)</td>\n",
       "      <td>2.008437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>(1810, 1792, 852, 811)</td>\n",
       "      <td>2.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>(1810, 720, 1879)</td>\n",
       "      <td>2.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>(1810, 1799, 720, 1792, 924, 811)</td>\n",
       "      <td>2.008461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1810, 924)</td>\n",
       "      <td>2.008472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>(825, 924, 838)</td>\n",
       "      <td>2.028795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>(852, 850, 811, 838)</td>\n",
       "      <td>2.028814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>(852, 798, 838)</td>\n",
       "      <td>2.028877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>(825, 852, 850, 838)</td>\n",
       "      <td>2.028904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>(798, 924, 850, 838)</td>\n",
       "      <td>2.028936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>(720, 924, 838)</td>\n",
       "      <td>2.028945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>(852, 924)</td>\n",
       "      <td>2.028996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(825, 850)</td>\n",
       "      <td>2.029010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>(852, 924, 850)</td>\n",
       "      <td>2.029039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>(825, 852, 838)</td>\n",
       "      <td>2.029047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>(852, 924, 838)</td>\n",
       "      <td>2.029141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>(852, 924, 850, 838)</td>\n",
       "      <td>2.029373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>(852, 798, 850)</td>\n",
       "      <td>2.029452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>(852, 798, 850, 838)</td>\n",
       "      <td>2.029463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>(720, 850, 838)</td>\n",
       "      <td>2.029864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>(850, 811, 838)</td>\n",
       "      <td>2.029880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>(825, 850, 838)</td>\n",
       "      <td>2.030005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(798, 838)</td>\n",
       "      <td>2.030260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>(798, 850, 838)</td>\n",
       "      <td>2.030367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>(811, 838)</td>\n",
       "      <td>2.030443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(924, 850)</td>\n",
       "      <td>2.030651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>(924, 850, 838)</td>\n",
       "      <td>2.030653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>(852, 850)</td>\n",
       "      <td>2.030788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(798, 850)</td>\n",
       "      <td>2.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>(852, 850, 838)</td>\n",
       "      <td>2.031067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>(720, 838)</td>\n",
       "      <td>2.031377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>(852, 838)</td>\n",
       "      <td>2.031454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(825, 838)</td>\n",
       "      <td>2.031714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(924, 838)</td>\n",
       "      <td>2.031851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>(850, 838)</td>\n",
       "      <td>2.033769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16368 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 models   mean_cv\n",
       "12                          (1810, 811)  2.006191\n",
       "3                           (1810, 720)  2.006598\n",
       "781              (1810, 720, 1792, 811)  2.007414\n",
       "766              (1810, 720, 1879, 811)  2.007568\n",
       "0                           (1810, 825)  2.007633\n",
       "881              (1810, 1792, 924, 811)  2.007861\n",
       "615              (1810, 825, 1792, 811)  2.008015\n",
       "585              (1810, 825, 720, 1792)  2.008061\n",
       "600              (1810, 825, 1879, 811)  2.008103\n",
       "583              (1810, 825, 720, 1879)  2.008145\n",
       "7                           (1810, 852)  2.008155\n",
       "832              (1810, 1879, 924, 811)  2.008174\n",
       "5326  (1810, 825, 720, 1879, 1792, 811)  2.008208\n",
       "149                    (1810, 720, 811)  2.008219\n",
       "6509  (1810, 720, 1879, 1792, 924, 811)  2.008255\n",
       "778              (1810, 720, 1792, 924)  2.008256\n",
       "777              (1810, 720, 1792, 798)  2.008268\n",
       "657              (1810, 1855, 720, 811)  2.008288\n",
       "2673        (1810, 720, 1792, 924, 811)  2.008303\n",
       "712              (1810, 1799, 720, 811)  2.008331\n",
       "774              (1810, 720, 1794, 811)  2.008357\n",
       "2609       (1810, 720, 1879, 1792, 811)  2.008390\n",
       "763              (1810, 720, 1879, 924)  2.008396\n",
       "2068        (1810, 825, 720, 1792, 811)  2.008435\n",
       "776              (1810, 720, 1792, 852)  2.008436\n",
       "5885  (1810, 1855, 720, 1792, 924, 811)  2.008437\n",
       "872              (1810, 1792, 852, 811)  2.008440\n",
       "141                   (1810, 720, 1879)  2.008456\n",
       "6215  (1810, 1799, 720, 1792, 924, 811)  2.008461\n",
       "9                           (1810, 924)  2.008472\n",
       "...                                 ...       ...\n",
       "267                     (825, 924, 838)  2.028795\n",
       "1908               (852, 850, 811, 838)  2.028814\n",
       "529                     (852, 798, 838)  2.028877\n",
       "1186               (825, 852, 850, 838)  2.028904\n",
       "1912               (798, 924, 850, 838)  2.028936\n",
       "433                     (720, 924, 838)  2.028945\n",
       "85                           (852, 924)  2.028996\n",
       "23                           (825, 850)  2.029010\n",
       "530                     (852, 924, 850)  2.029039\n",
       "258                     (825, 852, 838)  2.029047\n",
       "533                     (852, 924, 838)  2.029141\n",
       "1902               (852, 924, 850, 838)  2.029373\n",
       "526                     (852, 798, 850)  2.029452\n",
       "1896               (852, 798, 850, 838)  2.029463\n",
       "436                     (720, 850, 838)  2.029864\n",
       "558                     (850, 811, 838)  2.029880\n",
       "270                     (825, 850, 838)  2.030005\n",
       "94                           (798, 838)  2.030260\n",
       "546                     (798, 850, 838)  2.030367\n",
       "104                          (811, 838)  2.030443\n",
       "95                           (924, 850)  2.030651\n",
       "552                     (924, 850, 838)  2.030653\n",
       "86                           (852, 850)  2.030788\n",
       "91                           (798, 850)  2.030918\n",
       "536                     (852, 850, 838)  2.031067\n",
       "59                           (720, 838)  2.031377\n",
       "89                           (852, 838)  2.031454\n",
       "26                           (825, 838)  2.031714\n",
       "98                           (924, 838)  2.031851\n",
       "101                          (850, 838)  2.033769\n",
       "\n",
       "[16368 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combinations_df.sort_values(by='mean_cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RS=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>mean_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1810, 811)</td>\n",
       "      <td>2.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1810, 720)</td>\n",
       "      <td>2.006598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>(1810, 720, 1792, 811)</td>\n",
       "      <td>2.007414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>(1810, 720, 1879, 811)</td>\n",
       "      <td>2.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1810, 825)</td>\n",
       "      <td>2.007633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>(1810, 1792, 924, 811)</td>\n",
       "      <td>2.007861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>(1810, 825, 1792, 811)</td>\n",
       "      <td>2.008015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>(1810, 825, 720, 1792)</td>\n",
       "      <td>2.008061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>(1810, 825, 1879, 811)</td>\n",
       "      <td>2.008103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>(1810, 825, 720, 1879)</td>\n",
       "      <td>2.008145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1810, 852)</td>\n",
       "      <td>2.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>(1810, 1879, 924, 811)</td>\n",
       "      <td>2.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>(1810, 825, 720, 1879, 1792, 811)</td>\n",
       "      <td>2.008208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>(1810, 720, 811)</td>\n",
       "      <td>2.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>(1810, 720, 1879, 1792, 924, 811)</td>\n",
       "      <td>2.008255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>(1810, 720, 1792, 924)</td>\n",
       "      <td>2.008256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>(1810, 720, 1792, 798)</td>\n",
       "      <td>2.008268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>(1810, 1855, 720, 811)</td>\n",
       "      <td>2.008288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>(1810, 720, 1792, 924, 811)</td>\n",
       "      <td>2.008303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>(1810, 1799, 720, 811)</td>\n",
       "      <td>2.008331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>(1810, 720, 1794, 811)</td>\n",
       "      <td>2.008357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>(1810, 720, 1879, 1792, 811)</td>\n",
       "      <td>2.008390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>(1810, 720, 1879, 924)</td>\n",
       "      <td>2.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>(1810, 825, 720, 1792, 811)</td>\n",
       "      <td>2.008435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>(1810, 720, 1792, 852)</td>\n",
       "      <td>2.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>(1810, 1855, 720, 1792, 924, 811)</td>\n",
       "      <td>2.008437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>(1810, 1792, 852, 811)</td>\n",
       "      <td>2.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>(1810, 720, 1879)</td>\n",
       "      <td>2.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>(1810, 1799, 720, 1792, 924, 811)</td>\n",
       "      <td>2.008461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1810, 924)</td>\n",
       "      <td>2.008472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>(825, 924, 838)</td>\n",
       "      <td>2.028795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>(852, 850, 811, 838)</td>\n",
       "      <td>2.028814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>(852, 798, 838)</td>\n",
       "      <td>2.028877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>(825, 852, 850, 838)</td>\n",
       "      <td>2.028904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>(798, 924, 850, 838)</td>\n",
       "      <td>2.028936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>(720, 924, 838)</td>\n",
       "      <td>2.028945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>(852, 924)</td>\n",
       "      <td>2.028996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(825, 850)</td>\n",
       "      <td>2.029010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>(852, 924, 850)</td>\n",
       "      <td>2.029039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>(825, 852, 838)</td>\n",
       "      <td>2.029047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>(852, 924, 838)</td>\n",
       "      <td>2.029141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>(852, 924, 850, 838)</td>\n",
       "      <td>2.029373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>(852, 798, 850)</td>\n",
       "      <td>2.029452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>(852, 798, 850, 838)</td>\n",
       "      <td>2.029463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>(720, 850, 838)</td>\n",
       "      <td>2.029864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>(850, 811, 838)</td>\n",
       "      <td>2.029880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>(825, 850, 838)</td>\n",
       "      <td>2.030005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(798, 838)</td>\n",
       "      <td>2.030260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>(798, 850, 838)</td>\n",
       "      <td>2.030367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>(811, 838)</td>\n",
       "      <td>2.030443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(924, 850)</td>\n",
       "      <td>2.030651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>(924, 850, 838)</td>\n",
       "      <td>2.030653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>(852, 850)</td>\n",
       "      <td>2.030788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(798, 850)</td>\n",
       "      <td>2.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>(852, 850, 838)</td>\n",
       "      <td>2.031067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>(720, 838)</td>\n",
       "      <td>2.031377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>(852, 838)</td>\n",
       "      <td>2.031454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(825, 838)</td>\n",
       "      <td>2.031714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(924, 838)</td>\n",
       "      <td>2.031851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>(850, 838)</td>\n",
       "      <td>2.033769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32751 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 models   mean_cv\n",
       "12                          (1810, 811)  2.006191\n",
       "3                           (1810, 720)  2.006598\n",
       "781              (1810, 720, 1792, 811)  2.007414\n",
       "766              (1810, 720, 1879, 811)  2.007568\n",
       "0                           (1810, 825)  2.007633\n",
       "881              (1810, 1792, 924, 811)  2.007861\n",
       "615              (1810, 825, 1792, 811)  2.008015\n",
       "585              (1810, 825, 720, 1792)  2.008061\n",
       "600              (1810, 825, 1879, 811)  2.008103\n",
       "583              (1810, 825, 720, 1879)  2.008145\n",
       "7                           (1810, 852)  2.008155\n",
       "832              (1810, 1879, 924, 811)  2.008174\n",
       "5326  (1810, 825, 720, 1879, 1792, 811)  2.008208\n",
       "149                    (1810, 720, 811)  2.008219\n",
       "6509  (1810, 720, 1879, 1792, 924, 811)  2.008255\n",
       "778              (1810, 720, 1792, 924)  2.008256\n",
       "777              (1810, 720, 1792, 798)  2.008268\n",
       "657              (1810, 1855, 720, 811)  2.008288\n",
       "2673        (1810, 720, 1792, 924, 811)  2.008303\n",
       "712              (1810, 1799, 720, 811)  2.008331\n",
       "774              (1810, 720, 1794, 811)  2.008357\n",
       "2609       (1810, 720, 1879, 1792, 811)  2.008390\n",
       "763              (1810, 720, 1879, 924)  2.008396\n",
       "2068        (1810, 825, 720, 1792, 811)  2.008435\n",
       "776              (1810, 720, 1792, 852)  2.008436\n",
       "5885  (1810, 1855, 720, 1792, 924, 811)  2.008437\n",
       "872              (1810, 1792, 852, 811)  2.008440\n",
       "141                   (1810, 720, 1879)  2.008456\n",
       "6215  (1810, 1799, 720, 1792, 924, 811)  2.008461\n",
       "9                           (1810, 924)  2.008472\n",
       "...                                 ...       ...\n",
       "267                     (825, 924, 838)  2.028795\n",
       "1908               (852, 850, 811, 838)  2.028814\n",
       "529                     (852, 798, 838)  2.028877\n",
       "1186               (825, 852, 850, 838)  2.028904\n",
       "1912               (798, 924, 850, 838)  2.028936\n",
       "433                     (720, 924, 838)  2.028945\n",
       "85                           (852, 924)  2.028996\n",
       "23                           (825, 850)  2.029010\n",
       "530                     (852, 924, 850)  2.029039\n",
       "258                     (825, 852, 838)  2.029047\n",
       "533                     (852, 924, 838)  2.029141\n",
       "1902               (852, 924, 850, 838)  2.029373\n",
       "526                     (852, 798, 850)  2.029452\n",
       "1896               (852, 798, 850, 838)  2.029463\n",
       "436                     (720, 850, 838)  2.029864\n",
       "558                     (850, 811, 838)  2.029880\n",
       "270                     (825, 850, 838)  2.030005\n",
       "94                           (798, 838)  2.030260\n",
       "546                     (798, 850, 838)  2.030367\n",
       "104                          (811, 838)  2.030443\n",
       "95                           (924, 850)  2.030651\n",
       "552                     (924, 850, 838)  2.030653\n",
       "86                           (852, 850)  2.030788\n",
       "91                           (798, 850)  2.030918\n",
       "536                     (852, 850, 838)  2.031067\n",
       "59                           (720, 838)  2.031377\n",
       "89                           (852, 838)  2.031454\n",
       "26                           (825, 838)  2.031714\n",
       "98                           (924, 838)  2.031851\n",
       "101                          (850, 838)  2.033769\n",
       "\n",
       "[32751 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 20 \n",
    "k_range = range(2,15)\n",
    "\n",
    "all_combinations = []\n",
    "for k in k_range:\n",
    "    print(k)\n",
    "#     top_k = itertools.combinations(oof_preds_df.columns[:N],k)\n",
    "    top_k = itertools.combinations(oof_preds_df.columns,k)\n",
    "    for combo in top_k:\n",
    "        all_combinations.append([combo,simple_average(oof_preds_df[list(combo)])])\n",
    "\n",
    "all_combinations_df = pd.DataFrame(all_combinations, columns=['models','mean_cv'])\n",
    "\n",
    "all_combinations_df.sort_values(by='mean_cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RS=41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>mean_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1810, 720)</td>\n",
       "      <td>2.003472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>(1810, 720, 1794, 838)</td>\n",
       "      <td>2.004140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>(1810, 720, 1794, 850)</td>\n",
       "      <td>2.004171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>(1810, 720, 1794, 1792, 838)</td>\n",
       "      <td>2.004241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>(1810, 720, 1794, 1792, 850)</td>\n",
       "      <td>2.004269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>(1810, 720, 1794)</td>\n",
       "      <td>2.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>(1810, 720, 1794, 1792, 924)</td>\n",
       "      <td>2.004351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>(1810, 720, 1792, 850)</td>\n",
       "      <td>2.004448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>(1810, 720, 1792, 838)</td>\n",
       "      <td>2.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>(1810, 720, 1794, 1792, 850, 838)</td>\n",
       "      <td>2.004557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>(1810, 720, 1794, 1792, 924, 850)</td>\n",
       "      <td>2.004642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>(1810, 825, 720, 1794, 1792)</td>\n",
       "      <td>2.004659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>(1810, 720, 1794, 1792, 924, 838)</td>\n",
       "      <td>2.004686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>(1810, 825, 720, 1794, 1792, 838)</td>\n",
       "      <td>2.004759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>(1810, 825, 720, 1794, 1792, 850)</td>\n",
       "      <td>2.004792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>(1810, 720, 1792)</td>\n",
       "      <td>2.004808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>(1810, 720, 1792, 924)</td>\n",
       "      <td>2.004852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>(1810, 1855, 720, 1794, 838)</td>\n",
       "      <td>2.004893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11648</th>\n",
       "      <td>(1810, 1855, 720, 1794, 1792, 924, 838)</td>\n",
       "      <td>2.004894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>(1810, 720, 1794, 924)</td>\n",
       "      <td>2.004904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>(1810, 825, 720, 1794)</td>\n",
       "      <td>2.004914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>(1810, 720, 1794, 1792, 798)</td>\n",
       "      <td>2.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11651</th>\n",
       "      <td>(1810, 1855, 720, 1794, 1792, 850, 838)</td>\n",
       "      <td>2.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11645</th>\n",
       "      <td>(1810, 1855, 720, 1794, 1792, 924, 850)</td>\n",
       "      <td>2.004956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>(1810, 720, 1794, 1792, 811)</td>\n",
       "      <td>2.004956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>(1810, 1855, 720, 1794, 850)</td>\n",
       "      <td>2.004961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>(1810, 720, 1794, 1792, 798, 838)</td>\n",
       "      <td>2.004974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>(1810, 720, 1794, 798)</td>\n",
       "      <td>2.004977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>(1810, 720, 1794, 1792, 811, 838)</td>\n",
       "      <td>2.005008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>(1810, 825, 720, 1794, 1792, 924)</td>\n",
       "      <td>2.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>(852, 798, 924, 811)</td>\n",
       "      <td>2.025770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>(924, 850, 811)</td>\n",
       "      <td>2.025781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>(852, 798, 924)</td>\n",
       "      <td>2.025830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>(720, 811)</td>\n",
       "      <td>2.025857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>(852, 838)</td>\n",
       "      <td>2.025924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>(825, 852, 811)</td>\n",
       "      <td>2.025950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>(924, 811, 838)</td>\n",
       "      <td>2.026032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(924, 850)</td>\n",
       "      <td>2.026048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>(811, 838)</td>\n",
       "      <td>2.026053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(798, 850)</td>\n",
       "      <td>2.026144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>(825, 852, 924)</td>\n",
       "      <td>2.026157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>(798, 850, 811)</td>\n",
       "      <td>2.026303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>(852, 798, 811)</td>\n",
       "      <td>2.026308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>(825, 798, 811)</td>\n",
       "      <td>2.026365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>(852, 798)</td>\n",
       "      <td>2.026410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>(720, 924)</td>\n",
       "      <td>2.026496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(825, 798)</td>\n",
       "      <td>2.026572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>(852, 924, 811)</td>\n",
       "      <td>2.026601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>(798, 924, 811)</td>\n",
       "      <td>2.026703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(825, 852)</td>\n",
       "      <td>2.026704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(850, 811)</td>\n",
       "      <td>2.026815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>(825, 924, 811)</td>\n",
       "      <td>2.026871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>(852, 811)</td>\n",
       "      <td>2.027125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(924, 838)</td>\n",
       "      <td>2.027293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(798, 924)</td>\n",
       "      <td>2.027382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(825, 811)</td>\n",
       "      <td>2.028092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>(798, 811)</td>\n",
       "      <td>2.028132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>(852, 924)</td>\n",
       "      <td>2.028376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(825, 924)</td>\n",
       "      <td>2.028725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(924, 811)</td>\n",
       "      <td>2.029050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32751 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        models   mean_cv\n",
       "3                                  (1810, 720)  2.003472\n",
       "775                     (1810, 720, 1794, 838)  2.004140\n",
       "772                     (1810, 720, 1794, 850)  2.004171\n",
       "2638              (1810, 720, 1794, 1792, 838)  2.004241\n",
       "2635              (1810, 720, 1794, 1792, 850)  2.004269\n",
       "142                          (1810, 720, 1794)  2.004342\n",
       "2634              (1810, 720, 1794, 1792, 924)  2.004351\n",
       "779                     (1810, 720, 1792, 850)  2.004448\n",
       "782                     (1810, 720, 1792, 838)  2.004554\n",
       "6569         (1810, 720, 1794, 1792, 850, 838)  2.004557\n",
       "6563         (1810, 720, 1794, 1792, 924, 850)  2.004642\n",
       "2055              (1810, 825, 720, 1794, 1792)  2.004659\n",
       "6566         (1810, 720, 1794, 1792, 924, 838)  2.004686\n",
       "5355         (1810, 825, 720, 1794, 1792, 838)  2.004759\n",
       "5352         (1810, 825, 720, 1794, 1792, 850)  2.004792\n",
       "143                          (1810, 720, 1792)  2.004808\n",
       "778                     (1810, 720, 1792, 924)  2.004852\n",
       "2282              (1810, 1855, 720, 1794, 838)  2.004893\n",
       "11648  (1810, 1855, 720, 1794, 1792, 924, 838)  2.004894\n",
       "771                     (1810, 720, 1794, 924)  2.004904\n",
       "584                     (1810, 825, 720, 1794)  2.004914\n",
       "2633              (1810, 720, 1794, 1792, 798)  2.004939\n",
       "11651  (1810, 1855, 720, 1794, 1792, 850, 838)  2.004945\n",
       "11645  (1810, 1855, 720, 1794, 1792, 924, 850)  2.004956\n",
       "2637              (1810, 720, 1794, 1792, 811)  2.004956\n",
       "2279              (1810, 1855, 720, 1794, 850)  2.004961\n",
       "6562         (1810, 720, 1794, 1792, 798, 838)  2.004974\n",
       "770                     (1810, 720, 1794, 798)  2.004977\n",
       "6572         (1810, 720, 1794, 1792, 811, 838)  2.005008\n",
       "5351         (1810, 825, 720, 1794, 1792, 924)  2.005037\n",
       "...                                        ...       ...\n",
       "1892                      (852, 798, 924, 811)  2.025770\n",
       "551                            (924, 850, 811)  2.025781\n",
       "525                            (852, 798, 924)  2.025830\n",
       "58                                  (720, 811)  2.025857\n",
       "89                                  (852, 838)  2.025924\n",
       "257                            (825, 852, 811)  2.025950\n",
       "555                            (924, 811, 838)  2.026032\n",
       "95                                  (924, 850)  2.026048\n",
       "104                                 (811, 838)  2.026053\n",
       "91                                  (798, 850)  2.026144\n",
       "254                            (825, 852, 924)  2.026157\n",
       "545                            (798, 850, 811)  2.026303\n",
       "528                            (852, 798, 811)  2.026308\n",
       "262                            (825, 798, 811)  2.026365\n",
       "84                                  (852, 798)  2.026410\n",
       "55                                  (720, 924)  2.026496\n",
       "21                                  (825, 798)  2.026572\n",
       "532                            (852, 924, 811)  2.026601\n",
       "542                            (798, 924, 811)  2.026703\n",
       "20                                  (825, 852)  2.026704\n",
       "100                                 (850, 811)  2.026815\n",
       "266                            (825, 924, 811)  2.026871\n",
       "88                                  (852, 811)  2.027125\n",
       "98                                  (924, 838)  2.027293\n",
       "90                                  (798, 924)  2.027382\n",
       "25                                  (825, 811)  2.028092\n",
       "93                                  (798, 811)  2.028132\n",
       "85                                  (852, 924)  2.028376\n",
       "22                                  (825, 924)  2.028725\n",
       "97                                  (924, 811)  2.029050\n",
       "\n",
       "[32751 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 20 \n",
    "k_range = range(2,15)\n",
    "\n",
    "all_combinations = []\n",
    "for k in k_range:\n",
    "    print(k)\n",
    "#     top_k = itertools.combinations(oof_preds_df.columns[:N],k)\n",
    "    top_k = itertools.combinations(oof_preds_df.columns,k)\n",
    "    for combo in top_k:\n",
    "        all_combinations.append([combo,simple_average(oof_preds_df[list(combo)])])\n",
    "\n",
    "all_combinations_df = pd.DataFrame(all_combinations, columns=['models','mean_cv'])\n",
    "\n",
    "all_combinations_df.sort_values(by='mean_cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = score_df.loc[[1810, 825, 720, 1879, 1792, 811]]\n",
    "ensemble.to_csv('ensemble2_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>alg</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>filename</th>\n",
       "      <th>mad</th>\n",
       "      <th>n_folds</th>\n",
       "      <th>params_json</th>\n",
       "      <th>rs</th>\n",
       "      <th>score</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>884</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.058856</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.016929</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>123</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled_pc_0.05</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.020700</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>18</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled_pc_0.05</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.047044</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 1.0, \"bagging_freq\": 10, ...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.026146</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>953</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.049677</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.026580</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>866</td>\n",
       "      <td>lgb</td>\n",
       "      <td>more_features_lgb_eli_100</td>\n",
       "      <td>exp7.csv</td>\n",
       "      <td>0.046534</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.027478</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp7.csv_866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>109</td>\n",
       "      <td>lgb</td>\n",
       "      <td>standard_scaled</td>\n",
       "      <td>exp5.csv</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...</td>\n",
       "      <td>41</td>\n",
       "      <td>2.028996</td>\n",
       "      <td>True</td>\n",
       "      <td>lgb_exp5.csv_109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  alg                feature_set  filename       mad  n_folds  \\\n",
       "1810   884  lgb  more_features_lgb_eli_100  exp7.csv  0.058856     10.0   \n",
       "825    123  lgb    standard_scaled_pc_0.05  exp5.csv  0.041500     10.0   \n",
       "720     18  lgb    standard_scaled_pc_0.05  exp5.csv  0.047044     10.0   \n",
       "1879   953  lgb  more_features_lgb_eli_100  exp7.csv  0.049677     10.0   \n",
       "1792   866  lgb  more_features_lgb_eli_100  exp7.csv  0.046534     10.0   \n",
       "811    109  lgb            standard_scaled  exp5.csv  0.025882     10.0   \n",
       "\n",
       "                                            params_json  rs     score shuffle  \\\n",
       "1810  {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.016929    True   \n",
       "825   {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.020700    True   \n",
       "720   {\"bagging_fraction\": 1.0, \"bagging_freq\": 10, ...  41  2.026146    True   \n",
       "1879  {\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...  41  2.026580    True   \n",
       "1792  {\"bagging_fraction\": 0.5, \"bagging_freq\": 5, \"...  41  2.027478    True   \n",
       "811   {\"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"...  41  2.028996    True   \n",
       "\n",
       "              model_id  \n",
       "1810  lgb_exp7.csv_884  \n",
       "825   lgb_exp5.csv_123  \n",
       "720    lgb_exp5.csv_18  \n",
       "1879  lgb_exp7.csv_953  \n",
       "1792  lgb_exp7.csv_866  \n",
       "811   lgb_exp5.csv_109  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Test Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with RS=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.train import load_train_features, load_test_features, train_get_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb\n",
      "lgb\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2113]\tvalid_0's l1: 2.06799\n",
      "lgb\n",
      "lgb\n",
      "lgb\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[766]\tvalid_0's l1: 1.99697\n",
      "lgb\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "y_preds = {}\n",
    "# y_preds = []\n",
    "for idx,single_model in ensemble.iterrows():\n",
    "    print(single_model['alg'])\n",
    "    X_tr, y_tr = load_train_features(set = single_model['feature_set'])\n",
    "    X_test = load_test_features(set = single_model['feature_set'])\n",
    "    params = json.loads(single_model['params_json'])\n",
    "    alg = single_model['alg']\n",
    "    model_id = single_model['model_id']\n",
    "\n",
    "    model, y_pred = train_get_test_preds(X_tr, y_tr, X_test, params=params, alg=alg)\n",
    "    \n",
    "    y_preds[model_id] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../kaggle_files/submission/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f                0\n",
       "1  seg_0012b5                0\n",
       "2  seg_00184e                0\n",
       "3  seg_003339                0\n",
       "4  seg_0042cc                0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = pd.DataFrame(y_preds).T.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('ensemble2_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>3.316090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>4.623864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>5.678437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>8.359559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>6.478697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         3.316090\n",
       "1  seg_0012b5         4.623864\n",
       "2  seg_00184e         5.678437\n",
       "3  seg_003339         8.359559\n",
       "4  seg_0042cc         6.478697"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
